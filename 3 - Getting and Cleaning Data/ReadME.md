# Getting and Cleaning Data Project Read Me file
---
## Folder Structure

  Inside the Assignmet folder, there are 2 additional folders:<br>
  **1. /src** <br>
    Contains the script *run_analysis.R*
    
  **2. /datar** <br>
    Contains the input data set as a compacted file. It also contains another folder, *Tidy Data*, which contains the output file generated by *run_analysis* script.
   

---
## Running the script

  **1. Download the data and the script** <br>
    Download the file *getdata-projectfiles-UCI HAR Dataset.zip* from the data folder of this repository, and extract it on your computer.
 	Furthermore, save the file *run_analysis* into your computer<br>
    
  **2. Running the Script**<br>
    *run_analysis.R* scripts expects as input parameter the complete path where the data to be tidy is in. Thus, the directory must have the following structure:
         
* *root*
      * activity_labels.txt
      *	feateures.txt
	* */test*
      	* subject_test.txt
      	* X_test.txt
      	* y_test.txt
	* */train*
      	* subject_train.txt
      	* X_train.txt
      	* y_train.txt   
       
As output, the script creates a new folder on root directory, called *Tidy data*, as follows:

* *root*
	* */Tidy Data*
		* Tidy-Systemdatetime.txt

---
# About *run_analysis.R* file
This script is divided into 7 regions explained below.
##  1. REGION 1 - Reading Files
The goal is to check whether the folder passed as parameter exists, as well as the expected data files (listed above, on the Running the script section). If all folders and files exist, then all required files are loaded into the memory. Otherwise, a error message is thrown and the execution is stopped.
Thus, the following files are loaded:


1. *subjectTrain* - Subject's ids of each observation of the train set
2. *subjectTrain* - Subject's ids of each observation of the test set 
3. *activityNames* - Acitivies's Ids and Names
4. *featuresNames* - Features's names
5. *yTrain* - Predictions for the Train set observations. It stores the Activity ID of the predicted activity 
6. *yTest* - Predictions for the Train set observations. It stores the Activity ID of the predicted activity
7. *xTrain* - Observations of Train Set  
8. *yTrain* - Observations of Test Set 

##  2. REGION 2 - Merge Train and Test Datasets
In this section of the code, 3 data sets are created as result of the merge of observation files (X_--.txt), the prediction files, which represents the activity type (Y_--.txt) and the subject id file(subject_---.txt). The data sets are created binding all the rows of both test and train sets.
Therefore, these three data tables are created:

1. *mergedDataSet* - Stores all observations (Data Table)
2. *mergedLabels* - Stores all activities', for each observation (Data Table)
3. *subjectsMerged* - Stores all subject ids, for each observation (Vector)
	

##  3. REGION 3 - Select only features which represents either the mean or the standard deviation values of each feature
As all activities names are already loaded, at this point all of features which contains either "mean(" or "std(" in its name is selected by grep function with help of a regular expression (regex). The indexes of the features of interest are stored into *selectedFeatures* vector. Later on, this vector is used for subsetting the observations data table with only the features of interest (since is known that the observations follow the same order as the features names).

##  4. REGION 4 - Attaching the Activity's names into the observations Data Set
This region joins all activities labels from both test and train set with their respective names. In order to keep the original ordering of each row, an auxliary column *rowId* is created in *mergedLabels* dataset, in which it stores the row number.
Then, both *mergedLabels* and *activityNames* are joined by the *id* column of each data set and the result is stored into *mergedActivityNames* data set.
As the join operation sort all values of this new dataset by the activity id, the original ordering is obtained sortind the data by the *rowId* column.
Finally, all names are binded into the observations dataset, as well as the subject ids dataset.

## 5. REGION 5 - Labeling the data set with descriptive variable names
Names

## 6. REGION 6 - Grouping the data and calculating the average value of each variable
First, the data set is melt in order to turn each variable measure into a row. Then, data is grouped by both *Subject_id* and *Activity columns* in order to calculate the average value.
Finally, variable names are split into columns, and the remaining columns have their names ajusted.

## 7. REGION 7 - Writing data into a file
The output file is created at */root/Tidy Data* folder, and named as *Tidy-Datetime.txt* where *datetime* is the date and time when the file was created.
